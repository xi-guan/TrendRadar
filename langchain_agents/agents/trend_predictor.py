"""
Trend Predictor Agent

ä½¿ç”¨ LangGraph å®ç°çš„è¶‹åŠ¿é¢„æµ‹ Agentï¼Œå…·æœ‰å¤šæ­¥æ¨ç†å’ŒçŠ¶æ€ç®¡ç†èƒ½åŠ›ã€‚
"""

import logging
from typing import List, Dict, Any, Optional, TypedDict, Annotated
from operator import add

from langgraph.graph import StateGraph, END
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

from langchain_agents.config import get_config
from langchain_agents.tools.trendradar_tools import get_all_trendradar_tools


logger = logging.getLogger(__name__)


# ==================== State Definition ====================


class TrendPredictorState(TypedDict):
    """
    è¶‹åŠ¿é¢„æµ‹ Agent çš„çŠ¶æ€

    ä½¿ç”¨ TypedDict å®šä¹‰çŠ¶æ€ç»“æ„ï¼ŒAnnotated ç”¨äºæŒ‡å®šåˆå¹¶ç­–ç•¥ã€‚
    """
    # è¾“å…¥
    topic: str  # è¦åˆ†æçš„è¯é¢˜
    analysis_depth: str  # åˆ†ææ·±åº¦ ("quick", "standard", "deep")

    # ä¸­é—´çŠ¶æ€
    news_data: Optional[Dict[str, Any]]  # æ”¶é›†çš„æ–°é—»æ•°æ®
    trend_analysis: Optional[Dict[str, Any]]  # è¶‹åŠ¿åˆ†æç»“æœ
    prediction: Optional[str]  # é¢„æµ‹ç»“æœ
    confidence: Optional[float]  # é¢„æµ‹ç½®ä¿¡åº¦

    # è¾“å‡º
    final_report: Optional[str]  # æœ€ç»ˆæŠ¥å‘Š
    recommendations: Annotated[List[str], add]  # å»ºè®®åˆ—è¡¨ï¼ˆä½¿ç”¨ add è¿›è¡Œåˆå¹¶ï¼‰

    # å…ƒæ•°æ®
    steps_completed: Annotated[List[str], add]  # å·²å®Œæˆçš„æ­¥éª¤
    errors: Annotated[List[str], add]  # é”™è¯¯è®°å½•


# ==================== Node Functions ====================


def collect_news_node(state: TrendPredictorState) -> TrendPredictorState:
    """
    èŠ‚ç‚¹1: æ”¶é›†ç›¸å…³æ–°é—»

    ä½¿ç”¨ SearchNewsTool æ”¶é›†è¯é¢˜ç›¸å…³çš„æ–°é—»æ•°æ®ã€‚
    """
    topic = state["topic"]
    analysis_depth = state.get("analysis_depth", "standard")

    # æ ¹æ®åˆ†ææ·±åº¦å†³å®šæ”¶é›†çš„æ–°é—»æ•°é‡
    limit_map = {
        "quick": 20,
        "standard": 50,
        "deep": 100,
    }
    limit = limit_map.get(analysis_depth, 50)

    try:
        logger.info(f"Collecting news for topic: {topic} (limit={limit})")

        # è·å– TrendRadar å·¥å…· (P0 ä¿®å¤: æ·»åŠ é»˜è®¤å€¼é¿å… StopIteration)
        tools = get_all_trendradar_tools()
        search_tool = next((t for t in tools if t.name == "search_news"), None)

        if search_tool is None:
            error_msg = "search_news tool not found in available tools"
            logger.error(error_msg)
            return {
                **state,
                "news_data": {"error": error_msg, "count": 0, "news": []},
                "errors": [error_msg],
                "steps_completed": ["collect_news"],
            }

        # æœç´¢æ–°é—»
        result_json = search_tool._run(keyword=topic, platforms=None, limit=limit)

        import json
        news_data = json.loads(result_json)

        logger.info(f"Collected {news_data.get('count', 0)} news items")

        return {
            **state,
            "news_data": news_data,
            "steps_completed": ["collect_news"],
        }

    except Exception as e:
        error_msg = f"Failed to collect news: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return {
            **state,
            "news_data": {"error": error_msg, "count": 0, "news": []},
            "errors": [error_msg],
            "steps_completed": ["collect_news"],
        }


def analyze_trend_node(state: TrendPredictorState) -> TrendPredictorState:
    """
    èŠ‚ç‚¹2: åˆ†æè¶‹åŠ¿

    ä½¿ç”¨ AnalyzeTrendTool åˆ†æè¯é¢˜çš„è¶‹åŠ¿å˜åŒ–ã€‚
    """
    topic = state["topic"]
    news_data = state.get("news_data", {})

    try:
        logger.info(f"Analyzing trend for topic: {topic}")

        # è·å–åˆ†æå·¥å…· (P0 ä¿®å¤: æ·»åŠ é»˜è®¤å€¼é¿å… StopIteration)
        tools = get_all_trendradar_tools()
        analyze_tool = next((t for t in tools if t.name == "analyze_topic_trend"), None)

        if analyze_tool is None:
            error_msg = "analyze_topic_trend tool not found in available tools"
            logger.error(error_msg)
            return {
                **state,
                "trend_analysis": {"error": error_msg},
                "errors": [error_msg],
                "steps_completed": ["analyze_trend"],
            }

        # åˆ†æè¶‹åŠ¿
        result_json = analyze_tool._run(
            topic=topic,
            analysis_type="trend",
            date_range=None,
        )

        import json
        trend_analysis = json.loads(result_json)

        logger.info(f"Trend analysis completed for topic: {topic}")

        return {
            **state,
            "trend_analysis": trend_analysis,
            "steps_completed": ["analyze_trend"],
        }

    except Exception as e:
        error_msg = f"Failed to analyze trend: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return {
            **state,
            "trend_analysis": {"error": error_msg},
            "errors": [error_msg],
            "steps_completed": ["analyze_trend"],
        }


def generate_prediction_node(state: TrendPredictorState) -> TrendPredictorState:
    """
    èŠ‚ç‚¹3: ç”Ÿæˆé¢„æµ‹

    ä½¿ç”¨ LLM åŸºäºæ–°é—»æ•°æ®å’Œè¶‹åŠ¿åˆ†æç”Ÿæˆé¢„æµ‹ã€‚
    """
    topic = state["topic"]
    news_data = state.get("news_data", {})
    trend_analysis = state.get("trend_analysis", {})

    try:
        logger.info(f"Generating prediction for topic: {topic}")

        # è·å– LLM
        config = get_config()
        from langchain_openai import ChatOpenAI
        llm = ChatOpenAI(
            model=config.llm.model,
            temperature=config.llm.temperature + 0.2,  # é¢„æµ‹éœ€è¦æ›´é«˜åˆ›é€ æ€§
            max_tokens=config.llm.max_tokens * 2,
        )

        # æ„å»º Prompt
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è¶‹åŠ¿åˆ†æä¸“å®¶ï¼Œæ“…é•¿åŸºäºæ•°æ®é¢„æµ‹æœªæ¥å‘å±•ã€‚

ä»»åŠ¡ï¼šåŸºäºæä¾›çš„æ–°é—»æ•°æ®å’Œè¶‹åŠ¿åˆ†æï¼Œé¢„æµ‹è¯é¢˜çš„æœªæ¥å‘å±•æ–¹å‘ã€‚

è¦æ±‚ï¼š
1. åˆ†æå½“å‰è¶‹åŠ¿çš„é©±åŠ¨å› ç´ 
2. è¯†åˆ«å¯èƒ½çš„è½¬æŠ˜ç‚¹
3. é¢„æµ‹çŸ­æœŸï¼ˆ1-2å‘¨ï¼‰å’Œä¸­æœŸï¼ˆ1-3ä¸ªæœˆï¼‰å‘å±•
4. è¯„ä¼°é¢„æµ‹çš„ç½®ä¿¡åº¦
5. æä¾›æ•°æ®æ”¯æŒçš„ç†ç”±"""),
            ("human", """è¯é¢˜ï¼š{topic}

æ–°é—»æ•°æ®ï¼š
- æ–°é—»æ•°é‡ï¼š{news_count}
- æœ€æ–°æ–°é—»ï¼š{latest_news}

è¶‹åŠ¿åˆ†æï¼š
{trend_summary}

è¯·æä¾›è¯¦ç»†çš„è¶‹åŠ¿é¢„æµ‹ï¼š"""),
        ])

        # å‡†å¤‡æ•°æ®
        news_list = news_data.get("news", [])
        news_count = len(news_list)
        latest_news = "\n".join([
            f"- {news.get('title', 'N/A')}"
            for news in news_list[:5]
        ]) if news_list else "æ— æ–°é—»æ•°æ®"

        trend_summary = f"""
- çƒ­åº¦ï¼š{trend_analysis.get('heat', 'N/A')}
- è¶‹åŠ¿æ–¹å‘ï¼š{trend_analysis.get('trend_direction', 'N/A')}
- æ–°é—»æ•°é‡ï¼š{trend_analysis.get('news_count', 0)}
        """.strip()

        # ç”Ÿæˆé¢„æµ‹
        chain = prompt | llm | StrOutputParser()
        prediction = chain.invoke({
            "topic": topic,
            "news_count": news_count,
            "latest_news": latest_news,
            "trend_summary": trend_summary,
        })

        # ç®€å•çš„ç½®ä¿¡åº¦è¯„ä¼°ï¼ˆåŸºäºæ–°é—»æ•°é‡ï¼‰
        if news_count >= 50:
            confidence = 0.85
        elif news_count >= 20:
            confidence = 0.70
        elif news_count >= 10:
            confidence = 0.55
        else:
            confidence = 0.40

        logger.info(f"Prediction generated with confidence {confidence:.2f}")

        return {
            **state,
            "prediction": prediction,
            "confidence": confidence,
            "steps_completed": ["generate_prediction"],
        }

    except Exception as e:
        error_msg = f"Failed to generate prediction: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return {
            **state,
            "prediction": f"é¢„æµ‹ç”Ÿæˆå¤±è´¥ï¼š{error_msg}",
            "confidence": 0.0,
            "errors": [error_msg],
            "steps_completed": ["generate_prediction"],
        }


def generate_recommendations_node(state: TrendPredictorState) -> TrendPredictorState:
    """
    èŠ‚ç‚¹4: ç”Ÿæˆå»ºè®®

    åŸºäºé¢„æµ‹ç»“æœç”Ÿæˆå¯æ“ä½œçš„å»ºè®®ã€‚
    """
    topic = state["topic"]
    prediction = state.get("prediction", "")
    confidence = state.get("confidence", 0.0)

    try:
        logger.info(f"Generating recommendations for topic: {topic}")

        # åŸºäºç½®ä¿¡åº¦å’Œé¢„æµ‹å†…å®¹ç”Ÿæˆå»ºè®®
        recommendations = []

        if confidence >= 0.70:
            recommendations.append("âœ… é¢„æµ‹ç½®ä¿¡åº¦è¾ƒé«˜ï¼Œå»ºè®®å¯†åˆ‡å…³æ³¨è¯¥è¯é¢˜çš„å‘å±•")
        elif confidence >= 0.50:
            recommendations.append("âš ï¸  é¢„æµ‹ç½®ä¿¡åº¦ä¸­ç­‰ï¼Œå»ºè®®æ”¶é›†æ›´å¤šæ•°æ®åå†åšåˆ¤æ–­")
        else:
            recommendations.append("âŒ é¢„æµ‹ç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®è°¨æ…å‚è€ƒ")

        # ä»é¢„æµ‹ä¸­æå–å…³é”®å»ºè®®ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        if "ä¸Šå‡" in prediction or "å¢é•¿" in prediction:
            recommendations.append("ğŸ“ˆ è¶‹åŠ¿å‘ä¸Šï¼Œå»ºè®®æå‰å¸ƒå±€ç›¸å…³é¢†åŸŸ")
        elif "ä¸‹é™" in prediction or "å‡å°‘" in prediction:
            recommendations.append("ğŸ“‰ è¶‹åŠ¿å‘ä¸‹ï¼Œå»ºè®®è°ƒæ•´ç­–ç•¥æˆ–è§„é¿é£é™©")

        recommendations.append("ğŸ” å»ºè®®å®šæœŸï¼ˆæ¯å‘¨ï¼‰æ›´æ–°è¶‹åŠ¿åˆ†æä»¥è·Ÿè¸ªå˜åŒ–")

        logger.info(f"Generated {len(recommendations)} recommendations")

        return {
            **state,
            "recommendations": recommendations,
            "steps_completed": ["generate_recommendations"],
        }

    except Exception as e:
        error_msg = f"Failed to generate recommendations: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return {
            **state,
            "recommendations": [f"å»ºè®®ç”Ÿæˆå¤±è´¥ï¼š{error_msg}"],
            "errors": [error_msg],
            "steps_completed": ["generate_recommendations"],
        }


def create_final_report_node(state: TrendPredictorState) -> TrendPredictorState:
    """
    èŠ‚ç‚¹5: åˆ›å»ºæœ€ç»ˆæŠ¥å‘Š

    æ•´åˆæ‰€æœ‰åˆ†æç»“æœï¼Œç”Ÿæˆç»“æ„åŒ–çš„æœ€ç»ˆæŠ¥å‘Šã€‚
    """
    topic = state["topic"]
    news_data = state.get("news_data", {})
    trend_analysis = state.get("trend_analysis", {})
    prediction = state.get("prediction", "æ— é¢„æµ‹")
    confidence = state.get("confidence", 0.0)
    recommendations = state.get("recommendations", [])
    errors = state.get("errors", [])

    try:
        logger.info(f"Creating final report for topic: {topic}")

        # æ„å»ºæŠ¥å‘Š
        report_sections = [
            "=" * 60,
            f"è¶‹åŠ¿é¢„æµ‹æŠ¥å‘Šï¼š{topic}",
            "=" * 60,
            "",
            "## 1. æ•°æ®æ¦‚å†µ",
            f"- æ–°é—»æ•°é‡ï¼š{news_data.get('count', 0)}",
            f"- è¯é¢˜çƒ­åº¦ï¼š{trend_analysis.get('heat', 'N/A')}",
            f"- é¢„æµ‹ç½®ä¿¡åº¦ï¼š{confidence:.2%}",
            "",
            "## 2. è¶‹åŠ¿é¢„æµ‹",
            prediction,
            "",
            "## 3. å»ºè®®",
        ]

        for rec in recommendations:
            report_sections.append(f"  {rec}")

        if errors:
            report_sections.extend([
                "",
                "## âš ï¸  è­¦å‘Š",
                "åˆ†æè¿‡ç¨‹ä¸­å‡ºç°ä»¥ä¸‹é”™è¯¯ï¼š",
            ])
            for err in errors:
                report_sections.append(f"  - {err}")

        report_sections.extend([
            "",
            "=" * 60,
            f"å·²å®Œæˆæ­¥éª¤ï¼š{', '.join(state.get('steps_completed', []))}",
            "=" * 60,
        ])

        final_report = "\n".join(report_sections)

        logger.info("Final report created successfully")

        return {
            **state,
            "final_report": final_report,
            "steps_completed": ["create_final_report"],
        }

    except Exception as e:
        error_msg = f"Failed to create final report: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return {
            **state,
            "final_report": f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼š{error_msg}",
            "errors": [error_msg],
            "steps_completed": ["create_final_report"],
        }


# ==================== Graph Construction ====================


def create_trend_predictor_graph():
    """
    åˆ›å»ºè¶‹åŠ¿é¢„æµ‹ LangGraph

    è¿”å›ç¼–è¯‘åçš„å›¾
    """
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(TrendPredictorState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("collect_news", collect_news_node)
    workflow.add_node("analyze_trend", analyze_trend_node)
    workflow.add_node("generate_prediction", generate_prediction_node)
    workflow.add_node("generate_recommendations", generate_recommendations_node)
    workflow.add_node("create_final_report", create_final_report_node)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("collect_news")

    # æ·»åŠ è¾¹ï¼ˆå®šä¹‰æ‰§è¡Œæµç¨‹ï¼‰
    workflow.add_edge("collect_news", "analyze_trend")
    workflow.add_edge("analyze_trend", "generate_prediction")
    workflow.add_edge("generate_prediction", "generate_recommendations")
    workflow.add_edge("generate_recommendations", "create_final_report")
    workflow.add_edge("create_final_report", END)

    # ç¼–è¯‘å›¾
    app = workflow.compile()

    logger.info("TrendPredictorGraph compiled successfully")

    return app


# ==================== Agent Class ====================


class TrendPredictorAgent:
    """
    è¶‹åŠ¿é¢„æµ‹ Agent

    ä½¿ç”¨ LangGraph å®ç°çš„æœ‰çŠ¶æ€ Agentï¼Œå¯ä»¥æ‰§è¡Œå¤šæ­¥æ¨ç†ã€‚
    """

    def __init__(self):
        """åˆå§‹åŒ– Agent"""
        self.graph = create_trend_predictor_graph()
        logger.info("TrendPredictorAgent initialized")

    def predict(
        self,
        topic: str,
        analysis_depth: str = "standard",
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œè¶‹åŠ¿é¢„æµ‹

        Args:
            topic: è¦é¢„æµ‹çš„è¯é¢˜
            analysis_depth: åˆ†ææ·±åº¦ ("quick", "standard", "deep")

        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        try:
            logger.info(f"Starting trend prediction for: {topic} (depth={analysis_depth})")

            # åˆå§‹åŒ–çŠ¶æ€
            initial_state: TrendPredictorState = {
                "topic": topic,
                "analysis_depth": analysis_depth,
                "news_data": None,
                "trend_analysis": None,
                "prediction": None,
                "confidence": None,
                "final_report": None,
                "recommendations": [],
                "steps_completed": [],
                "errors": [],
            }

            # æ‰§è¡Œå›¾
            final_state = self.graph.invoke(initial_state)

            logger.info("Trend prediction completed successfully")

            return {
                "success": True,
                "topic": topic,
                "report": final_state.get("final_report", ""),
                "prediction": final_state.get("prediction", ""),
                "confidence": final_state.get("confidence", 0.0),
                "recommendations": final_state.get("recommendations", []),
                "steps_completed": final_state.get("steps_completed", []),
                "errors": final_state.get("errors", []),
            }

        except Exception as e:
            error_msg = f"Trend prediction failed: {str(e)}"
            logger.error(error_msg, exc_info=True)
            return {
                "success": False,
                "error": error_msg,
                "topic": topic,
            }

    async def apredict(
        self,
        topic: str,
        analysis_depth: str = "standard",
    ) -> Dict[str, Any]:
        """
        å¼‚æ­¥æ‰§è¡Œè¶‹åŠ¿é¢„æµ‹

        Args:
            topic: è¦é¢„æµ‹çš„è¯é¢˜
            analysis_depth: åˆ†ææ·±åº¦

        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        try:
            logger.info(f"Starting async trend prediction for: {topic}")

            initial_state: TrendPredictorState = {
                "topic": topic,
                "analysis_depth": analysis_depth,
                "news_data": None,
                "trend_analysis": None,
                "prediction": None,
                "confidence": None,
                "final_report": None,
                "recommendations": [],
                "steps_completed": [],
                "errors": [],
            }

            # å¼‚æ­¥æ‰§è¡Œå›¾
            final_state = await self.graph.ainvoke(initial_state)

            logger.info("Async trend prediction completed successfully")

            return {
                "success": True,
                "topic": topic,
                "report": final_state.get("final_report", ""),
                "prediction": final_state.get("prediction", ""),
                "confidence": final_state.get("confidence", 0.0),
                "recommendations": final_state.get("recommendations", []),
                "steps_completed": final_state.get("steps_completed", []),
                "errors": final_state.get("errors", []),
            }

        except Exception as e:
            error_msg = f"Async trend prediction failed: {str(e)}"
            logger.error(error_msg, exc_info=True)
            return {
                "success": False,
                "error": error_msg,
                "topic": topic,
            }
